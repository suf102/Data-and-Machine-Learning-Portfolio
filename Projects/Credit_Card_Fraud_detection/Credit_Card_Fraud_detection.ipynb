{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "In this notebook I will look to put together a credit card fraud detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First our dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, svm \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Later I will try to use s decision tree to see if it outperforms the other methods I will attempt in this notebook.\n",
    "from Decision_tree_classifier import *\n",
    "from Useful_tools import *\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing the data into pandas so we can begin our analysis.\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is this anonymized data that includes the 28 felids that represent some data about the transactions, an amount and a classification of fraud or not fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# To see the datatypes of our dataframe, as we can see the are all float 64s \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see the numebr of instances of fraud vs no fraud. We can see that the number of fraud cases is much larger than the no fraud cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "fearture_names = df.iloc[:,0:-1].columns\n",
    "target_name = df.iloc[:,-1:].columns\n",
    "feature_set = df[fearture_names]\n",
    "target_set = df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do our train test split of the data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set,target_set, test_size= 0.25 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice here how I have increased the maximum number of iterations from the usual 100, given the number of features and the size of the dataset more than the standard is needed\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running our test data through the model\n",
    "\n",
    "predictions = logistic_regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model above we are going to consider the precision and the recall. \n",
    "\n",
    "The precision is important because we want to know what our ratio of true positives are to total positives are. This tells use how often are we getting the wrong person. For fraud detection is is a measure of how much time the algorithm will waste by pursuing false positives. A number closer to one is better in this case. An algorithm that identifies everyone as fraudulent would catch every case of fraud but would be pointless. \n",
    "\n",
    "The recall is important because it tells us how many of the target category the model \"missed\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.79      0.55      0.65       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.90      0.77      0.82     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Now I will look to compare this to the classification tree that I have built in other notebooks in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same train test split for fairness (this might take a while to run)\n",
    "\n",
    "classifier = Tree_classifier(min_samples_split=3, max_depth=20)\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test)\n",
    "# print(accuracy_score(Y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
