{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "In this notebook I will look to put together a credit card fraud detection algorithm. The dataset is too large for github and can be found here (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First our dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, svm \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Later I will try to use s decision tree to see if it outperforms the other methods I will attempt in this notebook.\n",
    "from Decision_tree_classifier import *\n",
    "from Useful_tools import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing the data into pandas so we can begin our analysis.\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is this anonymized data that includes the 28 felids that represent some data about the transactions, an amount and a classification of fraud or not fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# To see the datatypes of our dataframe, as we can see the are all float 64s \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see the numebr of instances of fraud vs no fraud. We can see that the number of fraud cases is much larger than the no fraud cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = df.drop('Class', axis=1)\n",
    "target_set = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do our train test split of the data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set,target_set, test_size= 0.25 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice here how I have increased the maximum number of iterations from the usual 100, given the number of features and the size of the dataset more than the standard is needed\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running our test data through the model\n",
    "\n",
    "predictions = logistic_regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model above we are going to consider the precision and the recall. \n",
    "\n",
    "The precision is important because we want to know what our ratio of true positives are to total positives are. This tells use how often are we getting the wrong person. For fraud detection is is a measure of how much time the algorithm will waste by pursuing false positives. A number closer to one is better in this case. An algorithm that identifies everyone as fraudulent would catch every case of fraud but would be pointless. \n",
    "\n",
    "The recall is important because it tells us how many of the target category the model \"missed\". The ideal score is closer to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.79      0.55      0.65       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.90      0.77      0.82     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will look to compare this to the classification tree that I have built in other notebooks in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the decision tree classifier from SK learn \n",
    "\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.71      0.75      0.73       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.86      0.88      0.87     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the decision tree outperforms the logistic regression on the same data, on both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we are going to try a deep learning model on the same data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train dataset shape Counter({0: 227454, 1: 391})\n",
      "Sampled validation dataset shape Counter({0: 56861, 1: 101})\n"
     ]
    }
   ],
   "source": [
    "# The first thing that we need to do is to scale the data so we don't end up the data blow up issues. \n",
    "\n",
    "\n",
    "# Original dataset\n",
    "x = feature_set.values\n",
    "y = target_set.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Sampled train dataset shape %s' % Counter(y_train1))\n",
    "print('Sampled validation dataset shape %s' % Counter(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to bring it into pytorch and the torch dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "numeber_of_cores = 0\n",
    "\n",
    "training_dataset =  torch.utils.data.TensorDataset(torch.tensor(X_train1).float(), torch.tensor(y_train1).float())\n",
    "test_dataset =      torch.utils.data.TensorDataset(torch.tensor(X_test1).float(), torch.tensor(y_test1).float())\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset,batch_size=batch_size, num_workers = numeber_of_cores)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, num_workers = numeber_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self,n_input =10 , n_hidden = 15, n_output = 4, drop_prob = 0.5):\n",
    "        super().__init__()\n",
    "        self.extractor1 = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.extractor2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(drop_prob)\n",
    "        self.classifier = torch.nn.Linear(n_hidden,n_output)\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        x = self.relu(self.extractor1(x_batch))\n",
    "        x = self.relu(self.extractor2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, loss_function, x_batch , y_batch, opt = None):\n",
    "    loss = loss_function(model(x_batch),y_batch)\n",
    "    if opt is not None:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    return loss.item(), len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, loss_function, opt, train_dl, test_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            loss(model, loss_function,x_batch,y_batch,opt)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss(model, loss_function, xb, yb) for xb, yb in test_dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print(epoch, test_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train1.shape[1]\n",
    "n_output = 1\n",
    "n_hidden = 15\n",
    "\n",
    "model = Classifier(n_input=n_input,n_hidden=n_hidden,n_output=n_output,drop_prob=0.2)\n",
    "\n",
    "lr = 0.001\n",
    "    \n",
    "pos_weight = torch.tensor([5])\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "n_epoch = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04750505023104585\n",
      "1 0.046312091215026586\n",
      "2 0.044816451328682484\n",
      "3 0.0426001011423296\n",
      "4 0.0390692639730104\n",
      "5 0.035395833670869056\n",
      "6 0.03130622678524465\n",
      "7 0.027465325207410747\n",
      "8 0.024470260594191752\n",
      "9 0.022021906175647223\n",
      "10 0.020216764961667393\n",
      "11 0.0185268492104067\n",
      "12 0.017100198401112616\n",
      "13 0.01595285522615904\n",
      "14 0.014588161582529225\n",
      "15 0.01369090520646238\n",
      "16 0.013202954457635847\n",
      "17 0.012767917791329879\n",
      "18 0.012248269972148762\n",
      "19 0.011956292958386992\n",
      "20 0.011751944458906137\n",
      "21 0.011636225626540734\n",
      "22 0.011471668977377635\n",
      "23 0.011199772056579457\n",
      "24 0.011070527909871949\n",
      "25 0.011022785271131976\n",
      "26 0.011030282210083198\n",
      "27 0.011138066063456804\n",
      "28 0.011049538364996296\n",
      "29 0.010986717871120608\n",
      "30 0.010734494516943777\n",
      "31 0.010736600168059537\n",
      "32 0.010674387993514884\n",
      "33 0.010627931517888512\n",
      "34 0.010589207190504771\n",
      "35 0.010570850290925997\n",
      "36 0.010673509936797134\n",
      "37 0.010689056623922106\n",
      "38 0.010495415152621852\n",
      "39 0.010497422628780919\n",
      "40 0.01044879253514341\n",
      "41 0.010452533064588043\n",
      "42 0.01048871225470016\n",
      "43 0.010413504280493938\n",
      "44 0.010517978878485587\n",
      "45 0.01045960309895265\n",
      "46 0.010378427245527257\n",
      "47 0.010471022525955748\n",
      "48 0.010467412549486858\n",
      "49 0.01039251825045277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (extractor1): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (extractor2): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model,n_epoch,loss_func,opt,train_dataloader,test_dataloader)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56861\n",
      "           1       0.84      0.82      0.83       101\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.92      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = model(torch.tensor(X_test1).float()).detach().numpy()\n",
    "\n",
    "ypred [ypred>=0.5] =1.0\n",
    "ypred [ypred<0.5] =0.0\n",
    "print(metrics.classification_report(y_test1, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here the deep learning model as performed significantly better than the logistic regression model and beats out the decision tree. The training time remains reasonable, unlike the decision tree module. It does help that it can be trained with 4 parallel treads which the decision tree code I wrote cannot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
