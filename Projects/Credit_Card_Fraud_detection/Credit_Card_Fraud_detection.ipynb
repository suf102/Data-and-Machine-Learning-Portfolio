{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "In this notebook I will look to put together a credit card fraud detection algorithm. The dataset is too large for github and can be found here (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First our dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, svm \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Later I will try to use s decision tree to see if it outperforms the other methods I will attempt in this notebook.\n",
    "from Decision_tree_classifier import *\n",
    "from Useful_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing the data into pandas so we can begin our analysis.\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is this anonymized data that includes the 28 felids that represent some data about the transactions, an amount and a classification of fraud or not fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# To see the datatypes of our dataframe, as we can see the are all float 64s \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see the numebr of instances of fraud vs no fraud. We can see that the number of fraud cases is much larger than the no fraud cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the feature set from the target variable\n",
    "\n",
    "feature_set = df.drop('Class', axis=1)\n",
    "target_set = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do our train test split of the data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set,target_set, test_size= 0.25 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice here how I have increased the maximum number of iterations from the usual 100, given the number of features and the size of the dataset more than the standard is needed\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running our test data through the model\n",
    "\n",
    "predictions = logistic_regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model above we are going to consider the precision and the recall. \n",
    "\n",
    "The precision is important because we want to know what our ratio of true positives are to total positives are. This tells use how often are we getting the wrong person. For fraud detection is is a measure of how much time the algorithm will waste by pursuing false positives. A number closer to one is better in this case. An algorithm that identifies everyone as fraudulent would catch every case of fraud but would be pointless. \n",
    "\n",
    "The recall is important because it tells us how many of the target category the model \"missed\". The ideal score is closer to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.79      0.55      0.65       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.90      0.77      0.82     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will look to compare this to the classification tree that I have built in other notebooks in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the decision tree classifier from SK learn \n",
    "\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.70      0.77      0.73       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.85      0.88      0.87     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the decision tree outperforms the logistic regression on the same data, on both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we are going to try a deep learning model on the same data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train dataset shape Counter({0: 227451, 1: 394})\n",
      "Sampled validation dataset shape Counter({0: 56864, 1: 98})\n"
     ]
    }
   ],
   "source": [
    "# The first thing that we need to do is to scale the data so we don't end up with gradient explosion issues. \n",
    "\n",
    "\n",
    "# Original dataset\n",
    "x = feature_set.values\n",
    "y = target_set.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Sampled train dataset shape %s' % Counter(y_train1))\n",
    "print('Sampled validation dataset shape %s' % Counter(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to bring it into pytorch and the torch dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "numeber_of_cores = 3\n",
    "\n",
    "training_dataset =  torch.utils.data.TensorDataset(torch.tensor(X_train1).float(), torch.tensor(y_train1).float())\n",
    "test_dataset =      torch.utils.data.TensorDataset(torch.tensor(X_test1).float(), torch.tensor(y_test1).float())\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset,batch_size=batch_size, num_workers = numeber_of_cores)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, num_workers = numeber_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the neural network class defining a two layer model that has ReLu layers between\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self,n_input =10 , n_hidden = 15, n_output = 4, drop_prob = 0.5):\n",
    "        super().__init__()\n",
    "        # The first hidden layer\n",
    "        self.extractor1 = torch.nn.Linear(n_input, n_hidden)\n",
    "        # Second hidden layer\n",
    "        self.extractor2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        # A drop out for better learning\n",
    "        self.dropout = torch.nn.Dropout(drop_prob)\n",
    "        # The final layer that will pass out the classification\n",
    "        self.classifier = torch.nn.Linear(n_hidden,n_output)\n",
    "    # Forward pass of the data, taking it and   \n",
    "    def forward(self, x_batch):\n",
    "        x = self.relu(self.extractor1(x_batch))\n",
    "        x = self.relu(self.extractor2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, loss_function, x_batch , y_batch, opt = None):\n",
    "        # Using the loss function of choise to calculate the loss on each step\n",
    "    loss = loss_function(model(x_batch),y_batch)\n",
    "    # Just to make sure we arent going to throw and error if there isnt an actual optimiser to use.\n",
    "    if opt is not None:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    return loss.item(), len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model using a loop over the epochs\n",
    "\n",
    "def train(model, epochs, loss_function, opt, train_dl, test_dl):\n",
    "    for epoch in range(epochs):\n",
    "        # Making sure the model is in train mode\n",
    "        model.train()\n",
    "        # for each of the minibatches\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            loss(model, loss_function,x_batch,y_batch,opt)\n",
    "        # taking the model out of training mode and into testing mode so we can see wha the effect of the updated training is\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss(model, loss_function, xb, yb) for xb, yb in test_dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        # printing out the current loss, it also helps to know which epoch we are up to\n",
    "        print(epoch, test_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the model parameters, first the number of input variables \n",
    "\n",
    "n_input = X_train1.shape[1]\n",
    "\n",
    "# Setting the output so it predicts a single variable\n",
    "n_output = 1\n",
    "\n",
    "# settign the number of hidden layers\n",
    "n_hidden = 15\n",
    "\n",
    "model = Classifier(n_input=n_input,n_hidden=n_hidden,n_output=n_output,drop_prob=0.2)\n",
    "\n",
    "lr = 0.001\n",
    "    \n",
    "pos_weight = torch.tensor([5])\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "n_epoch = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.04725748244256418\n",
      "1 0.04628038090779906\n",
      "2 0.04515805190786762\n",
      "3 0.04370060727475822\n",
      "4 0.041636874152470464\n",
      "5 0.03845036037768262\n",
      "6 0.034695516415415156\n",
      "7 0.03104389619385274\n",
      "8 0.02769304709983489\n",
      "9 0.02496083291983036\n",
      "10 0.023149996318909558\n",
      "11 0.021530813588582415\n",
      "12 0.02021247885174549\n",
      "13 0.018949084009273195\n",
      "14 0.017751080452368284\n",
      "15 0.016936189923819345\n",
      "16 0.015974731791417486\n",
      "17 0.014768261023357316\n",
      "18 0.014197367658265533\n",
      "19 0.013693983091246082\n",
      "20 0.01319328531748977\n",
      "21 0.012961145447636624\n",
      "22 0.012555069195697249\n",
      "23 0.01233366859130388\n",
      "24 0.012141815214351984\n",
      "25 0.011965076259789702\n",
      "26 0.011999047852890164\n",
      "27 0.011701751205677657\n",
      "28 0.011587353204999436\n",
      "29 0.011452380232289285\n",
      "30 0.011325274080185611\n",
      "31 0.011192304881234077\n",
      "32 0.011182368759115963\n",
      "33 0.011211688293507794\n",
      "34 0.010931680082755831\n",
      "35 0.011045074568890248\n",
      "36 0.011097499528551012\n",
      "37 0.010885569511732817\n"
     ]
    }
   ],
   "source": [
    "train(model,n_epoch,loss_func,opt,train_dataloader,test_dataloader)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.79      0.80      0.79        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = model(torch.tensor(X_test1).float()).detach().numpy()\n",
    "\n",
    "ypred [ypred>=0.5] =1.0\n",
    "ypred [ypred<0.5] =0.0\n",
    "print(metrics.classification_report(y_test1, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here the deep learning model as performed significantly better than the logistic regression model and beats out the decision tree. The training time remains reasonable, unlike the decision tree module. It does help that it can be trained with 4 parallel treads which the decision tree code I wrote cannot. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
