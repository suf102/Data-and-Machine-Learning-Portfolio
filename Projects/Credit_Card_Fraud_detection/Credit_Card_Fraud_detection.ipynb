{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "In this notebook I will look to put together a credit card fraud detection algorithm. The dataset is too large for github and can be found here (https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First our dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "from sklearn import preprocessing, svm \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Later I will try to use s decision tree to see if it outperforms the other methods I will attempt in this notebook.\n",
    "from Decision_tree_classifier import *\n",
    "from Useful_tools import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing the data into pandas so we can begin our analysis.\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is this anonymized data that includes the 28 felids that represent some data about the transactions, an amount and a classification of fraud or not fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# To see the datatypes of our dataframe, as we can see the are all float 64s \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see the numebr of instances of fraud vs no fraud. We can see that the number of fraud cases is much larger than the no fraud cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_names = {0:'Not Fraud', 1:'Fraud'}\n",
    "print(df.Class.value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the feature set from the target variable\n",
    "\n",
    "feature_set = df.drop('Class', axis=1)\n",
    "target_set = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do our train test split of the data.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_set,target_set, test_size= 0.25 , random_state= 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice here how I have increased the maximum number of iterations from the usual 100, given the number of features and the size of the dataset more than the standard is needed\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "logistic_regression_model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running our test data through the model\n",
    "\n",
    "predictions = logistic_regression_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model above we are going to consider the precision and the recall. \n",
    "\n",
    "The precision is important because we want to know what our ratio of true positives are to total positives are. This tells use how often are we getting the wrong person. For fraud detection is is a measure of how much time the algorithm will waste by pursuing false positives. A number closer to one is better in this case. An algorithm that identifies everyone as fraudulent would catch every case of fraud but would be pointless. \n",
    "\n",
    "The recall is important because it tells us how many of the target category the model \"missed\". The ideal score is closer to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.79      0.55      0.65       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.90      0.77      0.82     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will look to compare this to the classification tree that I have built in other notebooks in this repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the decision tree classifier from SK learn \n",
    "\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "dataframe = pd.DataFrame(matrix, index=class_names, columns=class_names)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Blues\", fmt = 'g')\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.72      0.77      0.74       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.86      0.88      0.87     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the decision tree outperforms the logistic regression on the same data, on both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we are going to try a deep learning model on the same data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled train dataset shape Counter({0: 227451, 1: 394})\n",
      "Sampled validation dataset shape Counter({0: 56864, 1: 98})\n"
     ]
    }
   ],
   "source": [
    "# The first thing that we need to do is to scale the data so we don't end up with gradient explosion issues. \n",
    "\n",
    "\n",
    "# Original dataset\n",
    "x = feature_set.values\n",
    "y = target_set.values\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Sampled train dataset shape %s' % Counter(y_train1))\n",
    "print('Sampled validation dataset shape %s' % Counter(y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to bring it into pytorch and the torch dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "numeber_of_cores = 0\n",
    "\n",
    "training_dataset =  torch.utils.data.TensorDataset(torch.tensor(X_train1).float(), torch.tensor(y_train1).float())\n",
    "test_dataset =      torch.utils.data.TensorDataset(torch.tensor(X_test1).float(), torch.tensor(y_test1).float())\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset,batch_size=batch_size, num_workers = numeber_of_cores)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size, num_workers = numeber_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self,n_input =10 , n_hidden = 15, n_output = 4, drop_prob = 0.5):\n",
    "        super().__init__()\n",
    "        self.extractor1 = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.extractor2 = torch.nn.Linear(n_hidden, n_hidden)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(drop_prob)\n",
    "        self.classifier = torch.nn.Linear(n_hidden,n_output)\n",
    "        \n",
    "    def forward(self, x_batch):\n",
    "        x = self.relu(self.extractor1(x_batch))\n",
    "        x = self.relu(self.extractor2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.classifier(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, loss_function, x_batch , y_batch, opt = None):\n",
    "    loss = loss_function(model(x_batch),y_batch)\n",
    "    if opt is not None:\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    return loss.item(), len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, loss_function, opt, train_dl, test_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            loss(model, loss_function,x_batch,y_batch,opt)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss(model, loss_function, xb, yb) for xb, yb in test_dl])\n",
    "        test_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print(epoch, test_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = X_train1.shape[1]\n",
    "n_output = 1\n",
    "n_hidden = 15\n",
    "\n",
    "model = Classifier(n_input=n_input,n_hidden=n_hidden,n_output=n_output,drop_prob=0.2)\n",
    "\n",
    "lr = 0.001\n",
    "    \n",
    "pos_weight = torch.tensor([5])\n",
    "opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "n_epoch = 60\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.045979134650809855\n",
      "1 0.04446816525597078\n",
      "2 0.042604775786387286\n",
      "3 0.03945653231633412\n",
      "4 0.035083620741035756\n",
      "5 0.030846577382172256\n",
      "6 0.027092317249712904\n",
      "7 0.023936423051265605\n",
      "8 0.021323470456400706\n",
      "9 0.019289948248946094\n",
      "10 0.017458216051201333\n",
      "11 0.016292879066709714\n",
      "12 0.014932591604519282\n",
      "13 0.014540740054107684\n",
      "14 0.013377164563081776\n",
      "15 0.01306812161946162\n",
      "16 0.012511351181610193\n",
      "17 0.012360665667942704\n",
      "18 0.01210321293407593\n",
      "19 0.011833171703967521\n",
      "20 0.012016119678127378\n",
      "21 0.011782368364050031\n",
      "22 0.011337160676066901\n",
      "23 0.011430061176680334\n",
      "24 0.011305206283518348\n",
      "25 0.011181746844783944\n",
      "26 0.011003260229680567\n",
      "27 0.011311557042753486\n",
      "28 0.010846579783346239\n",
      "29 0.010979206437139523\n",
      "30 0.011167409090224324\n",
      "31 0.011002431253966608\n",
      "32 0.01081329149299584\n",
      "33 0.010689313676800647\n",
      "34 0.010743117331464422\n",
      "35 0.010897279924442877\n",
      "36 0.010884978500594144\n",
      "37 0.010762687379461022\n",
      "38 0.010950410697647248\n",
      "39 0.010590120046137444\n",
      "40 0.010587739817216604\n",
      "41 0.01065177696368447\n",
      "42 0.010492679946738526\n",
      "43 0.010585767212827585\n",
      "44 0.010465217172842628\n",
      "45 0.010471610569654337\n",
      "46 0.01052058476012029\n",
      "47 0.010458272361650417\n",
      "48 0.010426097820677398\n",
      "49 0.010420886737628915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (extractor1): Linear(in_features=30, out_features=15, bias=True)\n",
       "  (extractor2): Linear(in_features=15, out_features=15, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (classifier): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model,n_epoch,loss_func,opt,train_dataloader,test_dataloader)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.79      0.80      0.79        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.89      0.90      0.90     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred = model(torch.tensor(X_test1).float()).detach().numpy()\n",
    "\n",
    "ypred [ypred>=0.5] =1.0\n",
    "ypred [ypred<0.5] =0.0\n",
    "print(metrics.classification_report(y_test1, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here the deep learning model as performed significantly better than the logistic regression model and beats out the decision tree. The training time remains reasonable, unlike the decision tree module. It does help that it can be trained with 4 parallel treads which the decision tree code I wrote cannot. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
